{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Experiments\n",
    "---\n",
    "[Alejandro Ciuba](https://alejandrociuba.github.io), alejandrociuba@pitt.edu\n",
    "---\n",
    "## Summary\n",
    "\n",
    "Experiments for the text-only sentiment analysis models. We are trying the following models:\n",
    "- [SVC](#svc)\n",
    "- [Logistic Regression](#logistic-regression)\n",
    "- [Naive Bayes](#naive-bayes)\n",
    "    - [Multinomial](#multinomial-nb)\n",
    "    - [Compliment](#compliment-nb)\n",
    "- [One vs. Rest](#one-vs-rest)\n",
    "- [FFNN](#ffnn)\n",
    "- [LSTM](#lstm)\n",
    "\n",
    "For SVC, Logistic Regression, both Naive Bayes and FFNN (which will only accept string inputs and outputs) we will experiment with the following:\n",
    "- Count Vectors\n",
    "- TF-IDF Vectors\n",
    "- Gensim Custom Doc2Vec Vectors\n",
    "\n",
    "For LSTM\n",
    "- Gensim word2vec Vectors via [GoogleNews](https://code.google.com/archive/p/word2vec/)\n",
    "---\n",
    "## Setup\n",
    "### Necessary Imports\n",
    "#### Experiment Class & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import (Experiment,\n",
    "                        plot_confusion_matrix,\n",
    "                        vectorizer, )\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             precision_recall_fscore_support,\n",
    "                             confusion_matrix, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural import (FFNN,\n",
    "                    LSTM, )\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import (MultinomialNB,\n",
    "                                 ComplementNB, )\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import (CountVectorizer,\n",
    "                                             TfidfVectorizer, )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/final-splits.csv\"\n",
    "DATA = pd.read_csv(DATA_PATH, index_col=False)\n",
    "EMOTIONS = DATA.emotion.unique()\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "METRICS = {\"accuracy\": (accuracy_score, {}),\n",
    "           \"precision_recall_fscore_support\": (precision_recall_fscore_support, {\"average\": \"macro\", \"zero_division\": np.nan}),\n",
    "           \"confusion_matrix\": (confusion_matrix, {\"labels\": EMOTIONS}), }\n",
    "\n",
    "RESULTS = {\"experiment\": [],\n",
    "           \"accuracy\": [],\n",
    "           \"precision\": [],\n",
    "           \"recall\": [],\n",
    "           \"f1_score\": [], \n",
    "           \"comments\": [], }\n",
    "\n",
    "# Only run the experiments listed here; empty means run all\n",
    "targets = [\"LSTM/W2V\"]\n",
    "def selected(target):\n",
    "    if target in targets or len(targets) == 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "WTESTS = True  # Include and load word2vec experiments\n",
    "DTESTS = False  # Include and load doc2vec experiments\n",
    "\n",
    "if WTESTS:\n",
    "\n",
    "    WORD2VEC_PATH = \"../data/word2vec/GoogleNews-vectors-negative300.bin\"\n",
    "    W2V: KeyedVectors = KeyedVectors.load_word2vec_format(WORD2VEC_PATH, binary=True)\n",
    "\n",
    "if DTESTS:\n",
    "\n",
    "    DOC2VEC_PATH = \"../data/doc2vec-15-70.bin\"\n",
    "    D2V: Doc2Vec = Doc2Vec.load(DOC2VEC_PATH)\n",
    "\n",
    "STOPWORDS = stopwords.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(metrics, experiment, comments):\n",
    "\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    \n",
    "    prec, recall, f1, _ = metrics['precision_recall_fscore_support']\n",
    "\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "\n",
    "    plot_confusion_matrix(metrics['confusion_matrix'], labels=EMOTIONS)\n",
    "\n",
    "    RESULTS['experiment'].append(experiment)\n",
    "    RESULTS['accuracy'].append(metrics['accuracy'])\n",
    "    RESULTS['precision'].append(prec)\n",
    "    RESULTS['recall'].append(recall)\n",
    "    RESULTS['f1_score'].append(f1)\n",
    "    RESULTS['comments'].append(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_run(name, model, transforms, list_kwargs = None, comments = \"\", **kwargs):\n",
    "\n",
    "    exp = Experiment(name=name, data=DATA, model=model, comments=comments)\n",
    "\n",
    "    if transforms:\n",
    "        for i, transform in enumerate(transforms):\n",
    "            exp.transform(transform, **(list_kwargs[i] if list_kwargs else {}))\n",
    "\n",
    "    results = exp.full_run(metrics=METRICS, **kwargs)\n",
    "    display_results(results, name, comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_vector(name: str):\n",
    "\n",
    "    if name == \"count\":\n",
    "        return CountVectorizer(stop_words=\"english\", max_features=1_000)\n",
    "    elif name == \"tfidf\":\n",
    "        return TfidfVectorizer(stop_words=\"english\", max_features=1_000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_transform(X, y, subset):\n",
    "    return [[W2V[word] for word in simple_preprocess(sent) if word in W2V.key_to_index.keys()] for sent in X], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v_transform(X, y, subset):\n",
    "    return [D2V.infer_vector(simple_preprocess(sent)) for sent in X], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_TO_ID = {cat: i for i, cat in enumerate(DATA[\"emotion\"].unique())}\n",
    "ID_TO_CAT = {CAT_TO_ID[cat]: cat for cat in CAT_TO_ID}\n",
    "\n",
    "def cat_transform(X, y, subset):\n",
    "    return X, np.array([CAT_TO_ID[cat] for cat in y], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP1A = \"SVC/COUNT\"\n",
    "\n",
    "if selected(EXP1A):\n",
    "    exp_run(EXP1A, model=SVC(C=1), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"count\")}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP1B = \"SVC/TFIDF\"\n",
    "\n",
    "if selected(EXP1B):\n",
    "    exp_run(EXP1B, model=SVC(C=1), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"tfidf\")}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP1C = \"SVC/D2V\"\n",
    "\n",
    "if selected(EXP1C):\n",
    "    exp_run(EXP1C, model=SVC(C=1), transforms=[d2v_transform])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP2A = \"LOG/COUNT\"\n",
    "\n",
    "if selected(EXP2A):\n",
    "    exp_run(EXP2A, model=LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.5), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"count\")}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP2B = \"LOG/TFIDF\"\n",
    "\n",
    "if selected(EXP2B):\n",
    "    exp_run(EXP2B, model=LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.5), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"tfidf\")}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP2C = \"LOG/D2V\"\n",
    "\n",
    "if selected(EXP2C):\n",
    "    exp_run(EXP2C, model=LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.5), transforms=[d2v_transform])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Naive Bayes\n",
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP3A = \"MNB/COUNT\"\n",
    "\n",
    "if selected(EXP3A):\n",
    "    exp_run(EXP3A, model=MultinomialNB(), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"count\")}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP3B = \"MNB/TFIDF\"\n",
    "\n",
    "if selected(EXP3B):\n",
    "    exp_run(EXP3B, model=MultinomialNB(), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"tfidf\")}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compliment NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP4A = \"COM/COUNT\"\n",
    "\n",
    "if selected(EXP4A):\n",
    "    exp_run(EXP4A, model=ComplementNB(), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"count\")}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP4B = \"COM/TFIDF\"\n",
    "\n",
    "if selected(EXP4B):\n",
    "    exp_run(EXP4B, model=ComplementNB(), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"tfidf\")}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## One Vs. Rest\n",
    "\n",
    "For this, we will only run the best of the non-NN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP5A = \"ONE\"\n",
    "\n",
    "if selected(EXP5A):\n",
    "    exp_run(EXP5A, model=OneVsRestClassifier(MultinomialNB()), transforms=[vectorizer], list_kwargs=[{\"vect\": default_vector(\"count\")}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP6A = \"FFNN/D2V\"\n",
    "\n",
    "if selected(EXP6A):\n",
    "\n",
    "    def to_emotions(y_true, y_pred):\n",
    "        return [ID_TO_CAT[i] for i in y_true], [ID_TO_CAT[i] for i in y_pred]\n",
    "\n",
    "    numpy_transform = lambda X, y, subset: (np.array(X), y)\n",
    "\n",
    "    exp_run(EXP6A, model=FFNN(15, [10], 7, lr=1E-10), transforms=[d2v_transform, cat_transform, numpy_transform], epochs=4, batch_size=16, post=to_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (13300,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [ID_TO_CAT[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_true], [ID_TO_CAT[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_pred]\n\u001b[1;32m      8\u001b[0m numpy_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m X, y, subset: (np\u001b[38;5;241m.\u001b[39marray(X), y)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mexp_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXP6A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1E-10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mw2v_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumpy_transform\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_emotions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 7\u001b[0m, in \u001b[0;36mexp_run\u001b[0;34m(name, model, transforms, list_kwargs, comments, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transforms:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transforms):\n\u001b[0;32m----> 7\u001b[0m         \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlist_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlist_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mfull_run(metrics\u001b[38;5;241m=\u001b[39mMETRICS, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     10\u001b[0m display_results(results, name, comments)\n",
      "File \u001b[0;32m~/Documents/Programs/CS2756-Group-Project/Alejandro/experiment.py:50\u001b[0m, in \u001b[0;36mExperiment.transform\u001b[0;34m(self, operation, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_y \u001b[38;5;241m=\u001b[39m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_y \u001b[38;5;241m=\u001b[39m operation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_y, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_y \u001b[38;5;241m=\u001b[39m operation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_y, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[74], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(X, y, subset)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_emotions\u001b[39m(y_true, y_pred):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [ID_TO_CAT[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_true], [ID_TO_CAT[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_pred]\n\u001b[0;32m----> 8\u001b[0m numpy_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m X, y, subset: (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, y)\n\u001b[1;32m     10\u001b[0m exp_run(EXP6A, model\u001b[38;5;241m=\u001b[39mLSTM(\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m7\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1E-10\u001b[39m), transforms\u001b[38;5;241m=\u001b[39m[w2v_transform, cat_transform, numpy_transform], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, post\u001b[38;5;241m=\u001b[39mto_emotions)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (13300,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "EXP7A = \"LSTM/W2V\"\n",
    "\n",
    "if selected(EXP7A):\n",
    "\n",
    "    def to_emotions(y_true, y_pred):\n",
    "        return [ID_TO_CAT[i] for i in y_true], [ID_TO_CAT[i] for i in y_pred]\n",
    "\n",
    "    numpy_transform = lambda X, y, subset: (np.array(X), y)\n",
    "\n",
    "    exp_run(EXP6A, model=LSTM(300, 150, 64, 7, lr=1E-10), transforms=[w2v_transform, cat_transform, numpy_transform], epochs=4, batch_size=16, post=to_emotions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
